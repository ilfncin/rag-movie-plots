# ==========================
# Chunking Configuration
# ==========================
# Strategy options: character | token | recursive
CHUNK_STRATEGY=recursive
CHUNK_SIZE=1200
CHUNK_OVERLAP=200

# ==========================
# Embedding Model
# ==========================
# Embedding model used for ChromaDB (OpenAI)
EMBEDDING_MODEL=text-embedding-3-small

# ==========================
# Vectorstore Configuration
# ==========================
# Directory where the ChromaDB vector store will be persisted
PERSIST_DIR=db/chroma

# Name of the Chroma collection used to store embeddings
VECTORSTORE_COLLECTION_NAME=movie_plots

# ==========================
# Retriever Configuration
# ==========================
# Number of documents returned per query
RETRIEVER_TOP_K=10
# Maximum cosine distance allowed for a chunk to be considered relevant.
# Chunks with distance ABOVE this threshold are discarded after retrieval.
RETRIEVER_DISTANCE_THRESHOLD=0.35
# If true, returns ONLY chunks with distance <= RETRIEVER_DISTANCE_THRESHOLD (can return zero docs).
# If false, ignores threshold and always returns top-k.
RETRIEVER_USE_THRESHOLD=false

# ==========================
# LLM (OpenAI) Configuration
# ==========================
# Your OpenAI API key
OPENAI_API_KEY=your_api_key_here

# Model and temperature used for RAG responses
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.0